// Configuration

logging {
  level  = "warn"
  format = "logfmt"
}

livedebugging {
  enabled = true
}

// Data pipelines


//////////////////////////////////////////////
// Collect logs and metrics from external OTLP
//////////////////////////////////////////////

// External OTLP receiver authentication handler
otelcol.auth.bearer "home_external_auth" {
  token              = sys.env("OTLP_TOKEN")
}

// Create external OTLP receiver
otelcol.receiver.otlp "home_external" {
  http {
    endpoint         = "0.0.0.0:4318"
    auth             = otelcol.auth.bearer.home_external_auth.handler

    logs_url_path    = "/v1/logs"
    metrics_url_path = "/v1/metrics"
  }

  output {
    logs             = [otelcol.processor.batch.home_external.input]
    metrics          = [otelcol.processor.batch.home_external.input]
  }
}

// Batch external logs and metrics
otelcol.processor.batch "home_external" {
  output {
    logs             = [otelcol.exporter.loki.home_external.input]
    metrics          = [otelcol.exporter.prometheus.home_external.input]
  }
}

// Convert logs to Loki-based format
otelcol.exporter.loki "home_external" {
  forward_to         = [loki.write.home_external.receiver]
}

// Convert metrics to Prometheus-based format
otelcol.exporter.prometheus "home_external" {
  forward_to         = [prometheus.remote_write.home_external.receiver]
}

// Write logs to Loki
loki.write "home_external" {
  endpoint {
    url              = sys.env("ENDPOINT_LOKI")
  }
}

// Write metrics to VictoriaMetrics
prometheus.remote_write "home_external" {
  endpoint {
    url              = sys.env("ENDPOINT_VICTORIAMETRICS")
  }
}

//////////////////////////////////////////////


//////////////////////////////////////////////
// Collect logs from kubernetes pods
//////////////////////////////////////////////

// Discover pods
discovery.kubernetes "home_logs" {
  role            = "pod"
}

// [1] Aggregate logs
// Scrape logs from pods
discovery.relabel "home_logs" {
  targets         = discovery.kubernetes.home_logs.targets

  rule {
    source_labels = ["__meta_kubernetes_namespace"]
    action        = "replace"
    target_label  = "namespace"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_name"]
    action        = "replace"
    target_label  = "pod"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_container_name"]
    action        = "replace"
    target_label  = "container"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
    action        = "replace"
    target_label  = "app"
  }

  rule {
    source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
    action        = "replace"
    target_label  = "job"
    separator     = "/"
    replacement   = "$1"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
    action        = "replace"
    target_label  = "__path__"
    separator     = "/"
    replacement   = "/var/log/pods/*$1/*.log"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_container_id"]
    action        = "replace"
    target_label  = "container_runtime"
    regex         = "^(\\S+):\\/\\/.+$"
    replacement   = "$1"
  }
}

// Tail logs
loki.source.kubernetes "home_logs" {
  targets         = discovery.relabel.home_logs.output
  forward_to      = [loki.process.home_logs.receiver]
}

// [2] Aggregate logs
// Relabel logs
loki.process "home_logs" {
  stage.static_labels {
    values        = {
      "cluster"   = "home-k8s",
      "source"    = "kubernetes-logs",
    }
  }

  forward_to      = [loki.write.home_logs.receiver]
}

// Write logs to Loki
loki.write "home_logs" {
  endpoint {
    url           = sys.env("ENDPOINT_LOKI")
  }
}

//////////////////////////////////////////////



//////////////////////////////////////////////
// Collect metrics and traces from kubernetes pods
//////////////////////////////////////////////

// Auto-instrument collection of metrics and traces using Beyla
beyla.ebpf "home_discovery" {
  enforce_sys_caps             = true

  attributes {
    kubernetes {
      enable                   = "true"
      cluster_name             = "home-k8s"
    }

    select {
      attr                     = "*"
      include                  = ["*"]
      exclude                  = ["nothing"]
    }
  }

  discovery {
    instrument {
      kubernetes {
        namespace              = "*"
      }
      exports                  = ["metrics", "traces"]
    }

    exclude_instrument {
      kubernetes {
        namespace              = "cert-manager|default|k0s-autopilot|kube-node-lease|kube-public|kube-system|kubewall|longhorn|monitoring|speedtest"
      }
    }
  }

  ebpf {
    context_propagation        = "all"
    track_request_headers      = true
    high_request_volume        = true
    heuristic_sql_detect       = true
  }

  traces {
    instrumentations           = ["*"]
  }

  metrics {
    features = [
      "application",
      "application_process",
      "application_service_graph",
      "application_span",
    ]
    instrumentations           = ["*"]
  }

  output {
    traces                     = [otelcol.processor.batch.home_traces.input]
  }
}

// Batch traces
otelcol.processor.batch "home_traces" {
  output {
    traces                     = [otelcol.processor.span.home_spans_success.input]
  }
}

// Detect successful spans
otelcol.processor.span "home_spans_success" {
  include {
    match_type                 = "regexp"

    attribute {
      key                      = "http.response.status_code"
      value                    = "2[0-9]{2}"
    }
  }

  status {
    code                       = "Ok"
  }

  output {
    traces                     = [otelcol.processor.span.home_spans_fail.input]
  }
}

// Detect failed spans
otelcol.processor.span "home_spans_fail" {
  include {
    match_type                 = "regexp"

    attribute {
      key                      = "http.response.status_code"
      value                    = "5[0-9]{2}|4[0-9]{2}"
    }
  }

  status {
    code                       = "Error"
  }

  output {
    traces                     = [otelcol.exporter.otlphttp.home_traces.input]
  }
}

// Write traces to Tempo
otelcol.exporter.otlphttp "home_traces" {
  client {
    endpoint                   = sys.env("ENDPOINT_TEMPO")

    tls {
      insecure                 = true
      insecure_skip_verify     = true
    }
  }
}

// Scrape metrics from Beyla
prometheus.scrape "home_metrics" {
  targets                      = beyla.ebpf.home_discovery.targets

  honor_labels                 = true
  scrape_interval              = "10s"

  forward_to                   = [otelcol.receiver.prometheus.home_metrics.receiver]
}

// Convert metrics from Prometheus to OTLP-based format
otelcol.receiver.prometheus "home_metrics" {
  output {
    metrics                    = [otelcol.processor.filter.home_metrics.input]
  }
}

// [1] Aggregate metrics
// Drop unneeded IPs from trace service graph metrics of kind=server
otelcol.processor.filter "home_metrics" {
  error_mode                   = "ignore"

  metrics {
    datapoint = [
      `attributes["source"] == "beyla" and IsMatch(attributes["server"], "^([0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3})$")`,
    ]
  }

  output {
    metrics                    = [otelcol.processor.transform.home_metrics.input]
  }
}

// [2] Aggregate metrics
// Stack external IPs in trace service graph metrics of kind=client
// Relabel metrics
otelcol.processor.transform "home_metrics" {
  error_mode                   = "ignore"

  metric_statements {
    context                    = "datapoint"
    statements                 = [
      `set(attributes["client_address"], attributes["client"]) where IsMatch(attributes["client"], "^([0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3})$") and attributes["server"] == "skull-pc"`,
      `set(attributes["client"], "external-ip") where IsMatch(attributes["client_address"], "^([0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3})$") and attributes["server"] == "skull-pc"`,
      `set(attributes["cluster"], "home-k8s")`,
    ]
  }

  output {
    metrics                    = [otelcol.exporter.prometheus.home_metrics.input]
  }
}

// Convert metrics from OTLP to Prometheus-based format
otelcol.exporter.prometheus "home_metrics" {
  forward_to                   = [prometheus.remote_write.home_metrics.receiver]
}

// Write metrics to VictoriaMetrics
prometheus.remote_write "home_metrics" {
  endpoint {
    url                        = sys.env("ENDPOINT_VICTORIAMETRICS")
  }
}

//////////////////////////////////////////////
